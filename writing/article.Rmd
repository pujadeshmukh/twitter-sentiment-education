```{r include=FALSE}
require(pander)
require(knitcitations)
require(bibtex)
# biblio <- read.bib("../writing/ref.bib")
cite_options(numerical=TRUE)

load("../data/stream.rda")
# Pandoc.convert("../writing/article.md", format="docx")
```


Отношение к высшему образованию: сентимент-анализ данных микроблогов
========================================================
**Гедранович Б.А, Гедранович А.Б**
**********************************

#### Аннотация
В статье проводится сентимент-анализ сообщений в микроблогах *Twitter*, относящихся к высшему образованию. Было агрегировано `r nrow(stream)` тематических сообщений, проведен описательный анализ и выявлено обобщенное эмоциональное восприятие темы --- большинство сообщений носит нейтральный характер, количество положительных отзывов превышает количество отрицательных. Существенных отличий в распределении эмоциональных оценок по странам не выявлено.

#### Annotation
Article describes sentiment-analysis of *Twitter* 

Введение
------------------
Ключевым моментом в ведении любого бизнеса является исследование целевой аудитории. Это позволяет лучше узнать потребителей, сфокусировать свои усилия на удовлетворение их нужд. При оценке отношения потребителей к сложным продуктам, таким как образовательные услуги, туристические услуги, автомобили и пр., зачастую более важным является не столько рациональное, сколько эмоциональное восприятие товара. В качестве примера можно привести такие категории, как "*престиж вуза*" или "*элитарность образования*", которые в большей степени отражают субъективную (эмоциональную) составляющую оценки, нежели объективную (рациональную).

Современным инструментом оценки эмоционального восприятия продукта является сентимент-анализ (*Sentiment Analysis*) `r citep(c(liu2012="10.2200/S00416ED1V01Y201204HLT016"))`. Основной задачей данного подхода является определение субъективного восприятия продукта на основе семантического разбора текста. Конечные методики, используемые в рамках сентимент-анализа, могут варироваться от сравнительно простого словарного разбора предложений до сложных эвристических алгоритмов.

Развитие глобальной сети Интернет и сервисов, которые в ней предоставляются, дает неограниченные возможности для сбора маркетинговых данных о выбранной предметной области. В частности, микроблоги --- сервисы, позволяющие публиковать в сети короткие сообщения с помощью как стационарных, так и мобильных устройств, являются наиболее популярным способом агрегирования текстовой информации. Наиболее популярным сервисом микроблогов заслуженно считают *Twitter* `r citep("http://twitter.com")`, среди прочих достоинств которого можно отметить наличие программных интерфейсов (*Application Programming Interface --- API*), предоставляющих богатые возможности по автоматизации.

Данная работа призвана дать ответ на несколько вопросов:
* Как в целом потребители воспринимают высшее образование на эмоциональном уровне?
* Существует ли отличия в оценке высшего образования по странам?
* Как географически распределены положительные/отрицательные сообщения о высшем образовании?
* Какие географические регионы могут стать потенциальными рынками для экспорта белорусских образовательных услуг?

Мы рассматривали только англоязычную часть микроблогов, т.к., во-первых, охват большего количества языков является сложной технической задачей, выходящей за рамки нашего исследования, а во-вторых --- английский является основным языком академической среды *де факто*, следовательно, экспорт белорусских образовательных услуг нужно ориентировать на те регионы, где этот язык активно используется.

В первой части статьи приводится описание базовых техник, применяемых в сентимент-анализе, вторая часть посвящена вопросам, связанным со сбором и первичной обработкой данных, в третьей части описываются основные результаты и делаются выводы о проделанной работе.


1. Сентимент-анализ
------------------

Сентимент-анализ (анализ тональности) --- это раздел компьютерной лингвистики, в рамках которого изучается извлечение мнений и эмоциональной окрашенности текста. Как правило, с помощью анализа тональности выясняют отношение автора текста к рассматриваемой теме. Обычно такое отношение измеряют на простой шкале "положительное мнение" / "отрицательное мнение", более сложные системы предусматривают использование многоуровневой шкалы.

Анализ тональности нашел применение в различных областях: социология, политология, психология, медицина, маркетинг и др. В каждом конкретном случае могут ставиться отличные исследовательские или коммерческие задачи, однако используемый инструментарий чаще всего совпадает.

Подходы к классификации тональности можно разделить на следующие категории:
1. Использование набора "если-то".
2. Словарный разбор предложений.
3. Машинное обучение с учителем.
4. Машинное обучение без учителя `r sitep("http://habrahabr.ru/post/149605/")`.



Первый тип систем состоит из набора правил, применяя которые система делает заключение о тональности текста. Например, для предложения «Я люблю кофе», можно применить следующее правило:

если сказуемое ("люблю") входит в положительный набор глаголов ("люблю", "обожаю", "одобряю" ...) и в предложении не имеется отрицаний, то классифицировать тональность как "положительная"



Многие коммерческие системы используют данный подход, несмотря на то что он требует больших затрат, т.к. для хорошей работы системы необходимо составить большое количество правил. Зачастую правила привязаны к определенному домену (например, «ресторанная тематика») и при смене домена («обзор фотоаппаратов») требуется заново составлять правила. Тем не менее, этот подход является наиболее точным при наличии хорошей базы правил, но совершенно неинтересным для исследования.

Подходы, основанные на словарях, используют так называемые тональные словари (affective lexicons) для анализа текста. В простом виде тональный словарь представляет из себя список слов со значением тональности для каждого слова. Вот пример из базы ANEW, переведенный на русский:
слово   валентность (1-9)
счастливый 	8.21
хороший 	7.47
скучный 	2.95
сердитый 	2.85
грустный 	1.61


Чтобы проанализировать текст, можно воспользоваться следующим алгоритмом: сначала каждому слову в тексте присвоить его значением тональности из словаря (если оно присутствует в словаре), а затем вычислить общую тональность всего текста. Вычислять общую тональность можно разными способами. Самый простой из них — среднее арифметическое всех значений. Более сложный — обучить классификатор (напр. нейронная сеть).



Машинное обучение с учителем является наиболее распространенным методом, используемым в исследованиях. Его суть состоит в том, чтобы обучить машинный классификатор на коллекции заранее размеченных текстах, а затем использовать полученную модель для анализа новых документов. Именно про этот метод я расскажу далее.



Машинное обучение без учителя представляет собой, наверное, наиболее интересный и в то же время наименее точный метод анализа тональности. Одним из примеров данного метода может быть автоматическая кластеризация документов.



unsupervised learning for classification up/down recommendations `r citep(c(turney2002="10.3115/1073083.1073153"))` 

A latent variable model for geographic lexical variation `r citep(c(eisenstein2010="http://dl.acm.org/citation.cfm?id=1870782"))`


2. Данные
------------------
### Сбор данных
Служба микроблогов *Twitter* `r citep("http://twitter.com")` предоставляет несколько вариантов *API* для  доступа к данным. Первый из них --- это *Search API* `r citep("https://dev.twitter.com/docs/using-search")`, который позволяет осуществлять поиск сообщений по заданному запросу. Особенностями поиска с помощью этого программного интерфейса является ограничение на количество результатов, возвращаемых на запрос (текущее ограничение --- 1500 сообщений), отсутствие информации о географических координатах в результатах поиска, ограничение на количество запросов за заданный временной интервал. Более того, *Search API* предоставляет доступ только к приблизительно 6-8% всех сообщений за последнюю неделю.

Второй способ доступа к данным микроблогов -- это *Streaming API* `r citep("https://dev.twitter.com/docs/streaming-apis")`, отличительной особенностью которого является принципильной иной способ взаимодействия со службами *Twitter*. С помощью *Streaming API* можно подключиться к потоку сообщений микроблогов в режиме реального времени и агрегировать сообщения по мере их поступления. Таким образом можно добиться большего охвата данных по выбранным ключевым словам. Кроме того, при таком подходе можно отслеживать были ли входящие сообщения геокодированы (т.е. пользовательское устройство явно сообщило долготу и широту местоположения пользователя в момент отправления сообщения).

На практике только около 1% всех сообщений в *Twitter* являются геокодированными. Вместе с тем местоположения пользователя можно оценить и по данным его профиля, который заполняется во время регистрации в службе *Twitter*. Конечно же, указанные пользователем данные могут отличаться от действительности, поэтому требуется дополнительный шаг --- валидация данных профиля. Простым и эффективным способом решения данной задачи является проверка корректности географических названий по базе данных одной из географических служб. Среди прочих сервисов лидирующее положение занимает *GeoNames* `r citep("http://geonames.org")`, которая использовалась для определения географических координат по названию населенного пункта.

В настоящей работе использовалась комбинация двух *API*, предоставляемых службой *Twitter*, и внешнего сервиса *GeoNames* для получения информации о местоположении пользователя. Общий алгоритм сбора данных был следующим:

1. Подключение к потоку сообщений с помощью *Streaming API*, получение новых входящих сообщений по фильтру "*education,university,professor,college*".
2. Для каждого нового сообщения выделение следующих полей:
  * Идентификационный номер.
  * Дата и время создания.
  * Текст сообщения.
  * Язык сообщения.
3. Если сообщение геокодированное:
  * Выделение географических координат местоположения пользователя.
  * Запрос к службе _GeoNames_ для определения страны по географическим координатам.
4. Если сообщение не является геокодированным:
  * Выделение местоположения пользователя по данным, указанным в профиле (при необходимости, отправляется дополнительный запрос с помощью _Search API_).
  * Запрос к службе _GeoNames_ для распознавания местоположения пользователя.
  * Если распознавание прошло успешно --- выделение страны пользователя, и географических координат местоположения (города, штата, пр.).
5. Очистка текст сообщения от пунктуации, хэш-тэгов, удаление веб-ссылок, лишних пробелов, перевод в нижний регистр.
6. Если после всех манипуляций все необходимые поля заполнены корректно, сообщение регистрируется в базе данных.

Таким образом, в течение одной недели марта 2013 года было обработано и зарегистрировано `r nrow(stream)` сообщений микроблогов *Twitter* на английском языке, касающихся высшего образования.


3. Результаты
------------------



**Таблица 1.** Примеры положительных и отрицательных сообщений
```{r results='asis', echo=FALSE}
load("../writing/pos.neg.tweets.rda")
pandoc.table(tweets, style="rmarkdown", split.cells=Inf, split.tables=Inf)
# tweets
```


```{r fig.width=10, fig.height=6, echo=FALSE}
library(png)
library(grid)
img <- readPNG("../writing/figure/word.cloud.pos.png")
grid.raster(img)
```
**Рисунок 1.** Облако тегов для положительных сообщений


```{r fig.width=6, fig.height=6, echo=FALSE}
library(png)
library(grid)
img <- readPNG("../writing/figure/word.cloud.neg.png")
grid.raster(img)
```
**Рисунок 2.** Облако тегов для отрицательных сообщений


**Таблица 2.** Распределение сообщений по странам
```{r results='asis', echo=FALSE}
load("../writing/tweets.pandoc.rda")
pandoc.table(tweets.table, style="rmarkdown",
             round=2, decimal.mark=",", keep.trailing.zeros=T, split.tables=Inf)
```

```{r fig.width=10, fig.height=6, echo=FALSE}
library(png)
library(grid)
img <- readPNG("../writing/figure/map.png")
grid.raster(img)
```
**Рисунок 3.** Карта распределения сообщений

```{r fig.width=10, fig.height=4, echo=FALSE}
library(png)
library(grid)
img <- readPNG("../writing/figure/density.png")
grid.raster(img)
```
**Рисунок 4.** Плотность распределения оценок по выбранным странам


Заключение
------------------
Направления дальнейших исследований:
* Анализ сообщений в микроблогах на других языках.
* Сопоставление эмоциональных оценок сообщений с рейтингами университетов по странам.

Весь анализ был проведен на платформе *R* `r citep(citation())`, использовались пакеты *RCurl* `r citep(citation("RCurl"))`, *RJSONIO* `r citep(citation("RJSONIO"))` для агрегации данных от веб-служб *Twitter* и *GeoNames*, *ggplot2* `r citep(citation("ggplot2"))`, *wordcloud* `r citep(citation("wordcloud"))`, *rworldmap* `r citep(citation("rworldmap"))` --- для визуализации результатов, *plyr* `r citep(citation("plyr"))`, *stringr* `r citep(citation("stringr"))`, *data.table* `r citep(citation("data.table"))`--- для общей и статистической обработки данных, *tm* `r citep(citation("tm"))` --- для семантического анализа текста. Исходный программный код, использованный при написании статьи доступен по адресу `r citep("https://github.com/redmode/twitter-sentiment-education")`.


Литература
--------------
```{r results='asis', echo=FALSE}
bibliography()
```
